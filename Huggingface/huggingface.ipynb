{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\D'\n",
      "C:\\Users\\irumj\\AppData\\Local\\Temp\\ipykernel_6556\\799266458.py:2: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  loader=PyPDFDirectoryLoader('D:\\Data Science\\Langchain\\Huggingface\\Researchpapers')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'D:\\\\Data Science\\\\Langchain\\\\Huggingface\\\\Researchpapers\\\\2310.02557v3.pdf', 'page': 0}, page_content='Published as a conference paper at ICLR 2024\\nGENERALIZATION IN DIFFUSION MODELS ARISES FROM\\nGEOMETRY -ADAPTIVE HARMONIC REPRESENTATIONS\\nZahra Kadkhodaie\\nCtr. for Data Science, New York University\\nzk388@nyu.edu\\nFlorentin Guth\\nCtr. for Data Science, New York University\\nFlatiron Institute, Simons Foundation\\nflorentin.guth@nyu.edu\\nEero P. Simoncelli\\nNew York University\\nFlatiron Institute, Simons Foundation\\neero.simoncelli@nyu.edu\\nStéphane Mallat\\nCollège de France\\nFlatiron Institute, Simons Foundation\\nstephane.mallat@ens.fr\\nABSTRACT\\nDeep neural networks (DNNs) trained for image denoising are able to generate high-\\nquality samples with score-based reverse diffusion algorithms. These impressive\\ncapabilities seem to imply an escape from the curse of dimensionality, but recent\\nreports of memorization of the training set raise the question of whether these\\nnetworks are learning the “true” continuous density of the data. Here, we show')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the pdf frrom the folder\n",
    "loader=PyPDFDirectoryLoader('D:\\Data Science\\Langchain\\Huggingface\\Researchpapers')\n",
    "\n",
    "documents=loader.load()\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "\n",
    "final_documents=text_splitter.split_documents(documents)\n",
    "final_documents[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "657"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Data Science\\Langchain\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\Data Science\\Langchain\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\irumj\\.cache\\huggingface\\hub\\models--BAAI--bge-small-en-v1.5. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "#Huggingface Embbedings\n",
    "huggingface_embeddings=HuggingFaceBgeEmbeddings(\n",
    "    model_name='BAAI/bge-small-en-v1.5', #sentence-transformers/all-MiniLM-L6-v1\n",
    "    model_kwargs={\"device\":\"cpu\"},\n",
    "    encode_kwargs={'normalize_embeddings':True}\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.38528997e-02, -1.63743962e-02, -4.03489545e-03, -5.29999938e-03,\n",
       "        3.54662612e-02,  6.68298379e-02, -2.00018045e-02, -3.09520215e-02,\n",
       "        2.38293484e-02, -3.47777717e-02,  1.13824615e-02, -6.03083558e-02,\n",
       "        5.27293086e-02,  3.81362885e-02, -2.03825273e-02,  2.00199280e-02,\n",
       "        4.51154076e-03,  2.53979471e-02, -7.11156928e-04, -1.91773940e-02,\n",
       "       -2.16695573e-03, -2.62918584e-02,  4.63914266e-03, -4.75139283e-02,\n",
       "        1.12197828e-02, -3.39409299e-02,  4.89898622e-02, -2.77506970e-02,\n",
       "       -4.38967682e-02, -2.72081822e-01,  3.73184271e-02,  1.98525703e-03,\n",
       "        6.72558462e-03, -2.22141258e-02, -4.93949745e-04,  1.35471160e-02,\n",
       "        2.78016590e-02,  8.03616550e-03, -3.75419632e-02,  1.59666799e-02,\n",
       "       -3.01423259e-02, -8.64194427e-03,  3.16894799e-03, -1.49574978e-02,\n",
       "        3.53413746e-02, -5.19328518e-03, -2.97217742e-02, -8.15932527e-02,\n",
       "       -3.46349403e-02, -2.90952753e-02,  2.59444248e-02, -1.36671700e-02,\n",
       "        4.07021167e-03,  5.07926084e-02,  2.10217927e-02,  2.27257721e-02,\n",
       "        7.24555105e-02,  3.21962452e-03,  6.67590201e-02,  6.44916743e-02,\n",
       "       -1.03095034e-02,  6.06913157e-02, -1.11108683e-01,  1.04048634e-02,\n",
       "        2.42712516e-02,  4.08615842e-02, -1.10163148e-02, -3.99641469e-02,\n",
       "       -5.98699860e-02,  5.27506135e-02,  1.95461642e-02,  2.06911787e-02,\n",
       "       -2.82235742e-02,  3.56501490e-02,  7.54876807e-02,  2.97558028e-02,\n",
       "       -1.28033489e-03, -4.67472291e-03, -1.12860026e-02,  1.19938552e-02,\n",
       "        7.53766894e-02, -8.72599485e-05,  4.48635360e-03, -5.34208380e-02,\n",
       "       -2.79138610e-02,  6.36140443e-03, -1.12235742e-02, -5.94311021e-02,\n",
       "       -3.45054530e-02, -5.77855743e-02, -7.90208299e-03, -2.83163367e-03,\n",
       "       -8.92733037e-03,  4.33658361e-02, -4.44839932e-02, -1.06581967e-04,\n",
       "        2.77484674e-02,  3.73074636e-02,  6.15268722e-02,  3.79891455e-01,\n",
       "       -5.98575082e-03, -1.54523039e-02,  3.35797369e-02,  6.58335118e-03,\n",
       "       -3.02285310e-02, -3.55495848e-02, -1.94829796e-02,  9.20190848e-03,\n",
       "        1.77589583e-03,  4.90941927e-02, -3.65560986e-02, -6.63063303e-03,\n",
       "        4.07978427e-03, -1.58858765e-02, -1.27342073e-02, -5.77005036e-02,\n",
       "        2.21016500e-02,  2.87013743e-02,  2.45370120e-02, -2.44019888e-02,\n",
       "       -6.84446990e-02, -1.27134016e-02,  2.25977302e-02, -2.28003561e-02,\n",
       "        3.03123500e-02,  2.32322793e-03, -8.82484317e-02,  8.24535564e-02,\n",
       "        4.67336401e-02,  1.94211230e-02, -6.44392241e-03,  3.95027809e-02,\n",
       "       -1.01961561e-01,  2.78623924e-02,  2.27929521e-02,  1.31455762e-02,\n",
       "        3.88291217e-02, -1.08015994e-02, -4.49297838e-02,  6.33390769e-02,\n",
       "       -6.45791069e-02,  4.65185195e-02,  4.26692329e-02,  1.93441566e-02,\n",
       "       -1.01121612e-01,  1.04270391e-01, -7.06429482e-02, -1.24327075e-02,\n",
       "        2.74258642e-03, -4.51897606e-02,  3.37177739e-02,  5.66539690e-02,\n",
       "       -4.57805842e-02, -5.57417311e-02,  6.19058162e-02,  1.12013957e-02,\n",
       "       -8.69119598e-04, -3.68205048e-02, -7.24539012e-02,  1.76579878e-02,\n",
       "       -7.71383271e-02, -2.56858449e-02, -2.10031960e-02,  1.79313526e-01,\n",
       "       -7.54205743e-03,  3.58106615e-03, -2.87455656e-02,  7.68772676e-04,\n",
       "        2.78716162e-02, -1.66725777e-02,  1.59110799e-02,  1.30046513e-02,\n",
       "       -1.03157666e-02,  1.01025347e-02, -5.32271201e-03,  1.70997088e-03,\n",
       "       -5.72943017e-02, -8.42381045e-02, -1.43977804e-02, -1.16577204e-02,\n",
       "        1.24281030e-02, -2.62758620e-02, -1.23112220e-02,  1.06278965e-02,\n",
       "        2.11745556e-02, -5.79993725e-02, -1.92300025e-02,  3.53634427e-03,\n",
       "        1.60640460e-02,  5.90314418e-02,  8.22169892e-03,  1.02597494e-02,\n",
       "       -3.47059704e-02, -5.36992820e-03,  7.64225796e-03,  2.55342922e-03,\n",
       "       -4.47771698e-02,  3.83749306e-02, -4.91903238e-02,  1.14446483e-03,\n",
       "       -5.61083406e-02,  2.02470589e-02,  1.95903634e-03, -4.70998548e-02,\n",
       "       -1.47015583e-02,  9.18004010e-03,  3.30879614e-02, -2.42795236e-02,\n",
       "        1.59949884e-02,  5.26336804e-02, -2.15856750e-02, -3.30667235e-02,\n",
       "        7.95642659e-03, -2.57049780e-02,  3.51135693e-02,  4.58974130e-02,\n",
       "        4.28450704e-02, -2.23869774e-02, -3.91039997e-02,  2.44914945e-02,\n",
       "        2.19549052e-02, -1.61498096e-02, -9.90332589e-02, -3.13556731e-01,\n",
       "       -5.09516150e-02,  3.33091468e-02,  1.11269159e-02,  7.02838302e-02,\n",
       "       -1.27798066e-01,  5.53183667e-02, -6.43128809e-03,  6.18767329e-02,\n",
       "        6.82520121e-02, -3.15164104e-02,  3.23105194e-02, -2.73808725e-02,\n",
       "       -5.30399531e-02,  1.86321419e-02, -2.07786504e-02,  6.18478470e-02,\n",
       "        4.91559505e-02, -4.43157032e-02, -5.16251195e-03, -2.62522455e-02,\n",
       "        3.27884406e-02,  2.57422514e-02, -6.59675300e-02,  6.67571127e-02,\n",
       "        9.08824266e-04,  1.35576129e-01, -6.86527565e-02,  6.79886043e-02,\n",
       "        6.54541701e-02, -2.13870639e-03,  5.91474622e-02,  1.98404887e-03,\n",
       "       -2.97025982e-02,  3.83027382e-02, -3.77049227e-03,  9.42975059e-02,\n",
       "       -1.53890839e-02, -4.57129553e-02, -6.84972778e-02, -1.52015034e-02,\n",
       "        6.99831732e-03, -5.79905696e-03, -8.74611810e-02, -3.75433452e-02,\n",
       "        6.63917838e-03, -2.89647430e-02,  1.85823478e-02, -1.81756541e-02,\n",
       "        1.96641069e-02,  2.31888704e-02, -4.82722931e-02,  6.40551075e-02,\n",
       "       -3.75897177e-02, -1.23274839e-02, -4.01293999e-03, -5.12233078e-02,\n",
       "       -1.31256972e-02, -5.18518202e-02,  2.86161359e-02, -7.87899084e-03,\n",
       "       -6.04147911e-02, -1.18231503e-02,  6.97554508e-03,  1.16170826e-03,\n",
       "        7.94225372e-03,  2.35012397e-02, -3.68216820e-02, -1.21741125e-03,\n",
       "        7.31176697e-03, -1.73468571e-02,  8.69300216e-02, -5.90085145e-03,\n",
       "        2.27364749e-02,  4.21217866e-02,  1.34233208e-02, -1.47335483e-02,\n",
       "        8.12334660e-03, -6.58734143e-02,  8.43179505e-03,  4.79892120e-02,\n",
       "       -1.42377557e-03,  6.24870583e-02,  3.82407680e-02,  4.59204838e-02,\n",
       "        4.14187908e-02,  1.81945376e-02, -1.65373906e-02, -1.63933188e-02,\n",
       "        4.31337096e-02, -1.00602498e-02, -6.13708608e-03, -6.28916323e-02,\n",
       "       -2.86742169e-02,  2.63962965e-03,  2.15608627e-03, -2.01531380e-01,\n",
       "        1.03647998e-02,  1.54599780e-02,  1.06768623e-01,  2.66330354e-02,\n",
       "       -2.25985218e-02,  8.42738897e-03,  1.01164766e-02, -5.02641499e-03,\n",
       "       -6.03680946e-02, -2.42716707e-02,  6.60436675e-02,  8.52779672e-02,\n",
       "        4.65482660e-02,  3.01074255e-02, -1.15578726e-03,  2.62814239e-02,\n",
       "       -4.24913131e-02,  4.29471768e-02, -2.35476648e-03, -3.60836200e-02,\n",
       "        1.37290428e-03,  1.57160252e-01, -5.16215041e-02, -4.00854759e-02,\n",
       "       -3.82059067e-02, -1.54187884e-02, -4.72977720e-02, -5.66878021e-02,\n",
       "       -9.75050405e-03, -2.17196923e-02,  5.00847362e-02,  7.43213296e-02,\n",
       "       -1.73007846e-02,  3.66054885e-02,  8.86623338e-02,  1.66513026e-02,\n",
       "        3.09476405e-02,  3.50052230e-02, -4.90064621e-02,  4.73420694e-02,\n",
       "       -2.90767197e-02,  1.24858804e-02, -6.97579980e-03,  3.30324247e-02,\n",
       "        9.48551204e-03,  4.55647744e-02, -1.46121187e-02, -1.71567108e-02,\n",
       "        1.56264175e-02,  1.43603701e-03,  3.69021446e-02,  2.25129351e-02,\n",
       "        1.98945243e-04,  4.03105691e-02,  1.11161722e-02, -3.24912183e-02,\n",
       "       -2.14912146e-02,  1.43129257e-02, -3.01615074e-02,  1.15098860e-02,\n",
       "       -4.32153903e-02,  1.37370406e-02, -3.53182852e-02, -4.00885902e-02])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(huggingface_embeddings.embed_query(final_documents[0].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(384,)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(huggingface_embeddings.embed_query(final_documents[0].page_content)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorr Store\n",
    "vector_store=FAISS.from_documents(final_documents[:120],huggingface_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2, we perform SPT for Transformers and S4. Section 3.3 evaluates the role of design choices in\n",
      "SSMs in the context of SPT. Section 3.4 examines the utility of SPT across data scales and Section\n",
      "3.5 examines the utility of PT on a large text corpus. Section 3.6 provides an analysis of pretrained\n",
      "SSM kernels and how they relate to current initialization schemes. Section 3.7 contains additional\n",
      "experiments on distinct modalities.\n",
      "3.1 U NDERESTIMATION OF LONG -RANGE ABILITIES OF TRANSFORMERS\n",
      "We start by investigating the reliability of the historically-reported model performances on LRA, in\n",
      "the more modern setting of pretraining. Concretely, we repeat the Transformer experiments performed\n",
      "by Tay et al. (2020a), except that we first pretrain the model on the task data and then finetune it.\n",
      "To allow fair comparison with the original results, we strictly follow the model configurations used\n",
      "by Tay et al. (2020a). We experiment with two pretraining objectives: (1) next token prediction for\n"
     ]
    }
   ],
   "source": [
    "## Query using Similarity Search\n",
    "query=\"What is this Research Paper about\"\n",
    "relevant_document=vector_store.similarity_search(query)\n",
    "print(relevant_document[0].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags=['FAISS', 'HuggingFaceBgeEmbeddings'] vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002734D175EE0> search_kwargs={'k': 3}\n"
     ]
    }
   ],
   "source": [
    "retriver=vector_store.as_retriever(search_type = \"similarity\",search_kwargs={'k':3})\n",
    "print(retriver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ['HUGGINGFACEHUB_API_TOKEN']= ''\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is this Research Paper about?\\n\\nThe research paper is about the impact of the COVID-19 pandemic on the global economy and the measures taken by the government to mitigate the impact.\\n\\nWhat is the purpose of this Research Paper?\\n\\nThe purpose of this research paper is to analyze the impact of the COVID-19 pandemic on the global economy and the measures taken by the government to mitigate the impact.\\n\\nWhat are the key findings of this Research Paper?\\n\\nThe key findings of'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.llms import HuggingFaceHub\n",
    "hf= HuggingFaceHub(\n",
    "  repo_id='mistralai/Mistral-7B-v0.1',\n",
    "  model_kwargs={'temperature':0.1,'max_length':500}\n",
    " )\n",
    "query=\"What is this Research Paper about\"\n",
    "hf.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hugging Face models can be run locally through the HuggingFacePipeline class.\n",
    "#from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "\n",
    "#hf = HuggingFacePipeline.from_model_id(\n",
    " #   model_id=\"mistralai/Mistral-7B-v0.1\",\n",
    "  #  task=\"text-generation\",\n",
    "   # pipeline_kwargs={\"temperature\": 0, \"max_new_tokens\": 300})\n",
    "\n",
    "#llm = hf \n",
    "#llm.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=\"\"\"\n",
    "Use the following piece of context to answer the question.\n",
    "Please try to provide the answer based on the context\n",
    "{context}\n",
    "Question:{question}\n",
    "Helpful answer:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=PromptTemplate(template=prompt_template,input_variables=['context','question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "retrivelQA=RetrievalQA.from_chain_type(\n",
    "    llm=hf,\n",
    "    chain_type='stuff',\n",
    "    retriever=retriver,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={'prompt':prompt}\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"\"\"\n",
    "what is Gan About \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Use the following piece of context to answer the question.\n",
      "Please try to provide the answer based on the context\n",
      "Dec 2021.\n",
      "Z Kadkhodaie, F Guth, S Mallat, and E P Simoncelli. Learning multi-scale local conditional\n",
      "probability models of images. In Int’l Conf on Learning Representations (ICLR), Kigali, Rwanda,\n",
      "May 2023.\n",
      "T Karras, T Aila, S Laine, and J Lehtinen. Progressive growing of GANs for improved quality,\n",
      "stability, and variation. arXiv preprint arXiv:1710.10196, 2018.\n",
      "A. P. Korostelev and A. B. Tsybakov.Minimax theory of image reconstruction. Springer New York,\n",
      "NY , 1993.\n",
      "Z Liu, P Luo, X Wang, and X Tang. Deep learning face attributes in the wild. InProc Int’l Conference\n",
      "on Computer Vision (ICCV), Dec 2015.\n",
      "10\n",
      "\n",
      "large but realizable training sets (for our examples, roughly 105 images suffices), reflecting powerful\n",
      "inductive biases of these networks. Moreover, sampling from these models produces images of high\n",
      "visual quality, implying that these inductive biases are well-matched to the underlying distribution of\n",
      "photographic images (Wilson & Izmailov, 2020; Goyal & Bengio, 2022; Griffiths et al., 2023).\n",
      "To study these inductive biases, we develop and exploit the relationship between denoising and\n",
      "density estimation. We find that DNN denoisers trained on photographic images perform a shrinkage\n",
      "operation in an orthonormal basis consisting of harmonic functions that are adapted to the geometry\n",
      "of features in the underlying image. We refer to these asgeometry-adaptive harmonic bases (GAHBs).\n",
      "This observation, taken together with the generalization performance of DNN denoisers, suggests that\n",
      "optimal bases for denoising photographic images are GAHBs and, moreover, that inductive biases of\n",
      "\n",
      "This observation, taken together with the generalization performance of DNN denoisers, suggests that\n",
      "optimal bases for denoising photographic images are GAHBs and, moreover, that inductive biases of\n",
      "DNN denoisers encourage such bases. To test this more directly, we examine a particular class of\n",
      "images whose intensity variations are regular over regions separated by regular contours. A particular\n",
      "type of GAHB, known as “bandlets” (Peyré & Mallat, 2008), have been shown to be near-optimal for\n",
      "denoising these images (Dossal et al., 2011). We observe that the DNN denoiser operates within a\n",
      "GAHB similar to a bandlet basis, also achieving near-optimal performance. Thus the inductive bias\n",
      "enables the network to appropriately estimate the score in these cases.\n",
      "If DNN denoisers induce biases towards the GAHB approximation class, then they should perform\n",
      "sub-optimally for distributions whose optimal bases are not GAHBs. To investigate this, we train\n",
      "Question:\n",
      "what is Gan About \n",
      "\n",
      "Helpful answer:\n",
      "\n",
      "GANs are a type of machine learning algorithm that are used to generate new data that is similar to existing data. They are often used in image generation and natural language processing.\n",
      "\n",
      "GANs are composed of two neural networks: a generator and a discriminator. The generator is responsible for creating new data, while the discriminator is responsible for determining whether the new data is real or fake. The two networks compete against each other, with the generator trying to create data that is indist\n"
     ]
    }
   ],
   "source": [
    "#Call the QA chain with  our query\n",
    "results=retrivelQA.invoke({'query':query})\n",
    "print(results['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
